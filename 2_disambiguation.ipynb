{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二元文法文本消岐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from match import Match\n",
    "from hmm import HMM\n",
    "from nlputils import * \n",
    "from bigram import Bigram\n",
    "\n",
    "import jieba\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入训练语料，并处理成训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file_path = './corpus/2021.txt'\n",
    "dest_folder = './states/'\n",
    "states_file_path = dest_folder + os.path.basename(text_file_path)\n",
    "# text_to_state(text_file_path, dest_folder)\n",
    "corpus = read_corpus_or_states_for_hmm(text_file_path)\n",
    "states = read_corpus_or_states_for_hmm(states_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在前面的步骤中，使用五折交叉验证说明了训练语料具有很强的泛化性\n",
    "\n",
    "因此，为了保证和后续平滑的数据一致，这里选择不打乱数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = yield_data(zip(corpus, states), shuffle=False)\n",
    "corpus_train, states_train = zip(*train)\n",
    "corpus_test, states_test = zip(*test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将训练语料处理成可以给Match使用的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['站', '在', '“', '两个', '一百年', '”', '奋斗目标', '的', '历史', '交汇点']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_train = corpus_to_vocab(corpus_train)\n",
    "vocab_train[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "传入训练语料，训练获得最大正向、最大逆向和HMM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm = HMM()\n",
    "hmm.train(corpus_train, states_train)\n",
    "forward_match = Match(\"max_forward\", vocab_train)\n",
    "backwad_match = Match(\"max_backward\", vocab_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试正向逆向模型的分词结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['今天', '天气', '不错'], ['今天', '天气', '不错'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_match.tokenize(\"今天天气不错\"), backwad_match.tokenize(\"今天天气不错\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练使用训练语料训练消岐二元模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bigram import Bigram\n",
    "bigram_model = Bigram()\n",
    "bigram_model.train(corpus=corpus_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "消岐，将概率最大的句子返回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "jieba_res = []\n",
    "output_folder = './results/'\n",
    "f = open(os.path.join(output_folder, 'disambiguation_result.txt'), 'w', encoding='utf-8')\n",
    "for test in corpus_test:\n",
    "    # test是jieba分词的结果\n",
    "    test = test.replace(\" \", \"\")\n",
    "    states, hmm_tokens = hmm.tokenize(test)\n",
    "    forward_tokens = forward_match.tokenize(test)\n",
    "    backward_tokens = backwad_match.tokenize(test)\n",
    "    jieba_tokens = jieba.lcut(test, cut_all=False)\n",
    "\n",
    "    tokens = bigram_model.disambiguation([hmm_tokens, forward_tokens, backward_tokens])\n",
    "    \n",
    "    # 写入\n",
    "    for token in tokens:\n",
    "        if token != tokens[-1]:\n",
    "            f.write(token + ' ')\n",
    "        else:\n",
    "            f.write(token + '\\n')\n",
    "            \n",
    "    res += tokens\n",
    "    jieba_res += jieba_tokens\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算消岐后的PRF值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9003080292107398, 0.8857426426702301, 0.8929659449925084)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real, pred, correct = cal_count(jieba_res, res)\n",
    "p, r, f = cal_prf(real, pred, correct)\n",
    "p, r, f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "计算正向匹配和逆向匹配的PRF值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_res = []\n",
    "backward_res = []\n",
    "jieba_res = []\n",
    "i = 0\n",
    "for test in corpus_test:\n",
    "    test = test.replace(\" \", \"\")\n",
    "    forward_tokens = forward_match.tokenize(test)\n",
    "    backward_tokens = backwad_match.tokenize(test)\n",
    "    jieba_tokens = jieba.lcut(test, cut_all=False)\n",
    "\n",
    "    forward_res += forward_tokens\n",
    "    backward_res +=  backward_tokens\n",
    "    jieba_res += jieba_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9336170412659082, 0.9250713972441629, 0.9293245742111881)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_f, pred_f, correct_f = cal_count(jieba_res, forward_res)\n",
    "p, r, f = cal_prf(real_f, pred_f, correct_f)\n",
    "p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9368913434645046, 0.9288318815299679, 0.9328442050581789)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_b, pred_b, correct_b = cal_count(jieba_res, backward_res)\n",
    "p, r, f = cal_prf(real_b, pred_b, correct_b)\n",
    "p, r, f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "res = []\n",
    "jieba_res = []\n",
    "output_folder = './results/'\n",
    "f = open(os.path.join(output_folder, 'disambiguation_result_supplement.txt'), 'w', encoding='utf-8')\n",
    "for test in corpus_test:\n",
    "    # test是jieba分词的结果\n",
    "    test = test.replace(\" \", \"\")\n",
    "    states, hmm_tokens = hmm.tokenize(test)\n",
    "    forward_tokens = forward_match.tokenize(test)\n",
    "    backward_tokens = backwad_match.tokenize(test)\n",
    "    jieba_tokens = jieba.lcut(test, cut_all=False)\n",
    "    # 等概率选择正向逆向的结果\n",
    "    relative_tokens = forward_tokens if random.random()*100 >= 50 else backward_tokens\n",
    "\n",
    "    tokens = bigram_model.disambiguation([hmm_tokens, relative_tokens])\n",
    "    \n",
    "    # 写入\n",
    "    for token in tokens:\n",
    "        if token != tokens[-1]:\n",
    "            f.write(token + ' ')\n",
    "        else:\n",
    "            f.write(token + '\\n')\n",
    "            \n",
    "    res += tokens\n",
    "    jieba_res += jieba_tokens\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8820670705870199, 0.864406852610636, 0.8731476721754845)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real, pred, correct = cal_count(jieba_res, res)\n",
    "p, r, f = cal_prf(real, pred, correct)\n",
    "p, r, f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
